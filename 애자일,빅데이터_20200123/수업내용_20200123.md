# 수업내용_20200123

* 프로젝트수행방법론

  보통 많은 회사들이 waterfall모델을 많이 쓰고 있다. 점점 나중에 50%는 애자일방법론으로 갈아탈 것이다.

  - waterfall모델은 현장의 거의 대부분의 프로젝트는 초기에 상세 개발계획을 모두 수립하고 요구분석->설계->코딩->테스트 등 순차적으로 개발을 진행하고 산출물 중심으로 관리하는 방식이다.
  - 애자일방법론은 워터풀모델과 달리 뒤 단계를 미리 예측하며 개발하지 않고, 일정한 반복주기를 가지고 끊임없이 프로토타입을 만들어 내며 필요할 때마다 요구사항을 더하고 수정하여 커다란 소프트웨어를 개발해 나가는 방식이다. 이 과정 가각에 이해관계자를 참여시켜 요구사항 수집과 결과 검증을 모두 거쳐갈 수 있는 장점이 있다.
  - 다만 애자일방법론은 많은 문제점이 있어서 회사에서 사용하려고 하지 않는다.
  - 애자일이 성공률이 낮은 이유는
    1. 고객은 자주 참여를 하지 않는 프로젝트를 선호한다.
    2. 팀원들이 느끼기에는 애자일방법론은 계속해서 소규모프로젝트를 하는 느낌으로 부담감을 줄 수 있다.
    3. 실제로 의사검증하는 기간이 길어질 수 있다. 바로 의사결정해주질 않는 경우가 많다.
    4. 팀원이 결정해버리는 과정에 실수가 발생할 수 있다. 신입인 경우 본인일만 아는 경우가 많기 때문에 사용자를 만나서 할 수 없는 요구를 받아들이는 실수를 범할 수 있다.

* 프로젝트착수단계 주의사항

  - 리더를 선임하고 팀원별 명확한 역할과 책임을 정립하자.

  - 팀 내의 협의하에 프로젝트기본규칙을 정립하자.

  - WBS기반으로 체계적인 공정계획을 수립하자.

    여기서 WBS는 프로젝트 일정을 관리하기 위해 단계별 활동내역을 정의한 후 활동간의 선후행관계, 수행기간을 정의하여 일정계획을 수립하고 활동별 담당자를 배정하여 만든 공정계획 문서를 의미한다.

    ﻿

    

    ![image.png](https://blogfiles.pstatic.net/MjAyMDAxMjNfODkg/MDAxNTc5NzUwNTU1OTA2.KhRgJMy8-ZGMiZaJ3_7ZVs8oX4YSNByhVma1gqI76p4g.GW8dCThPGPwOmLwhynM2QYxxpZs4s3ApwCrg2r8VVRAg.PNG.yumin9838/image.png?type=w1)

    대표사진 삭제

    사진 설명을 입력하세요.

    ﻿



---프로젝트 일정계획 수립시 고려해야 할 사항

1. 개발 내역에 대한 기술적인 난이도를 사전에 평가해야 한다.

2. 업무를 담당하는 팀원 각각의 능력을 고려

3. 개발과정에서 예상치 못한 이슈가 발생하는 경우가 많기 때문에

4. 이슈를 해결할 버퍼를 고려해서 일정을 계획하는 것이 바람직함

   버퍼란 처음 계획한 기간에서 마지막주를 남겨두는데 이 마지막주를 버퍼라고 함

   

   * 개발 전 목표 시스템에 대한 체계적인 설계를 수행해라
     - it프로젝트에서 설계가 중요한 이유는
       1. 기능, 데이터, uI, 아키텍쳐 요구사항 등을 고려한 체계적인 설계를 통해
       2. 불필요한 코드를 줄이고 테스트와 재작업이 쉬운 코드를 만들어내며
       3. 개발과정에서 무한 수정/변경 등의 삽질을 방지할 수 있을 뿐만 아니라
       4. 향후 수정 및 유지보수가 용이하여 운영 생산성이 향상될 수 있음
   * 분업이 아닌 협업을 수행하라

* 4차산업혁명이란? 관통하는 핵심 키워드는 connectivity+intelligence

* 빅데이터란? 

  * 자연발생적으로 나온 이름이 아니다.

  * 2001년 3v정의: Volume,Velocity,Variety

    2012년 기존 정의개정-큰 용량, 빠른 속도, 그리고 높은 다양성을 갖는 정보자산으로 이를 통해 의사결정 및 통찰 발견, 프로세스의 최적화를 향상시키기 위해 새로운 형태의 처리방식필요. 즉 3v데이터를 가지고 처리하는 방식이 필요

    IBM 4v정의: 기존 3v에 진실성(Veracity)추구

    Brian Hopkins 4v정의: 기존 3v에 가변성(variability)추가

    Mckinsey: 일반적인 데이터베이스 SW가 저장, 관리, 분석할 수 있는 범위를 초과하는 규모의 데이터

    IDC: 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고 데이터의 초고속 수진, 발굴, 분석을 지원하도록 고안된 차세대 기술 및 아키텍쳐

  * \

* 기업이 원하는 것은 무엇인가? 빅데이터로 얻고자 하는 것은? 회사는 미래를 알고 싶다.

  #  --->예측모델

* 예측모델링기법->>엔트로피, 의사결정나무(decision tree)

  - 엔트로피

    어떤 집합에 대한 무질서 정도를 측정한 값

    방정식: 엔트로피= - p1*log(p1) - p2log(p2) -  -------

    여기서 Pi는 집합 안에서 속성i의 확률

    엔트로피는 1에가까울수록 안정적이지만 0에가까울수록 분류가 잘 되었다고 말한다. 

    속성과 타겟밸류를 봐야 하는데 각 속성들의 엔트로피와 타겟벨류의 엔트로피를 알고 있으면 

    정보증가량을 알 수 있다. 

  - 정보증가량(information gain)

    IG(parents, children) = entropy(parents)- [p(c1)*entropy(c1)+p(c2)*entropy(c2)+ ------]

    왜 확률을 곱해주는가? 가중치를 두기 위해서

    ### 여기서 왜 IG를 배울까?

    - 데이터베이스 셋을 봤을 때 타겟분류가 모두 같은 값이 나왔을 때 알고리즘 스탑함
    - 같은 값이 아니라면 segmentation시켜->가로든 세로든no끼리, yes끼리 분류
    - 여기서 조각내는 기준이 필요하다.기준이 IG인셈

  - 의사결정나무

    의사결정나무를 만드는 것이 목표이기 때문에 IG를 구하는 것이다.각 속성별로 IG를 구한 뒤더 높은 값으로 분류하고 Y,,N가 나오지 않은 값들은 또다시 IG를 구한 뒤 쪼갭니다. 이런식으로 모두 같은 값이 나올때까지 segmentation을 한 뒤 다 같은 값이 나오면 알고리즘 쪼개는 것은 스탑. 하나의 의사결정나무가 만들어진다.

    이 의사결정나무는 프로그래밍에서 IF 라고 생각하면 됩니다.

  - 왜 예측모델링에서 이렇게 깊이 들어가는 것이냐면, 나중에 툴을 쓸 때 모두가 표준으로 쓰면

    경쟁이 되지 않는데 툴에서 공식만 바꿔줘도 엔트로피가 바뀌고, IG가 바뀌고 하기 때문이다.

    우리 기업만의 툴이 되고 표준툴과 우리만의 툴 등 다양한 툴로 데이터를 관리해서 분류하다보면 신뢰도가 쌓이게 됩니다. 

* 우리는 여기를 왜 와서 훈련을 받는가? 6개월동안 프로젝트를 하기 위해서 왔다. 

  프로젝트를 하면서 사실 다 잘할 수 없고 그 중 잘하는 사람이 프로젝트를 도맡아 할 가능성이 높다. 그럴 때 제일 잘 하는 사람의 말을 이해할 수 있을 정도로 잘 알고 있어야 내가 따라갈 수 있어야 면접을 볼 때 내가 한 것 같이 말할 수 있다. 다 외우든 뭐든 해서 내가 다 만든 것같이 알고 가야 한다. 

* 그리고 잘 부탁하자 . 먼저 못하는 것은 부탁하면서 배우는게 제일 좋다. 

* 관심이 있으면 빅테이터 책을 많이 읽어보자.






